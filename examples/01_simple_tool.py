"""ç¬¬ 1 è¯¾ï¼šç†è§£å·¥å…·è°ƒç”¨

æœ¬è¯¾ç›®æ ‡ï¼š
- äº†è§£ OpenAI Function Calling çš„å·¥ä½œæœºåˆ¶
- æ‰‹åŠ¨è°ƒç”¨ä¸€ä¸ªå·¥å…·å¹¶å°†ç»“æœè¿”å›ç»™ LLM
- è§‚å¯Ÿ LLM å¦‚ä½•å†³å®šè°ƒç”¨å·¥å…·ä»¥åŠå¦‚ä½•ä½¿ç”¨å·¥å…·ç»“æœ

è¿è¡Œæ–¹å¼ï¼š
    python -m examples.01_simple_tool
"""

import json
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.llm import LLMClient
from src.tools.calculator import CalculatorTool


def main():
    # ---- æ­¥éª¤ 1ï¼šåˆå§‹åŒ– LLM å’Œå·¥å…· ----
    print("=" * 60)
    print("ç¬¬ 1 è¯¾ï¼šç†è§£å·¥å…·è°ƒç”¨")
    print("=" * 60)

    llm = LLMClient()
    calculator = CalculatorTool()

    # å°†å·¥å…·è½¬æ¢ä¸º OpenAI æ ¼å¼
    tools = [calculator.to_openai_tool()]
    print(f"\nå·¥å…·å®šä¹‰ï¼ˆOpenAI æ ¼å¼ï¼‰ï¼š")
    print(json.dumps(tools, indent=2, ensure_ascii=False))

    # ---- æ­¥éª¤ 2ï¼šå‘é€åŒ…å«å·¥å…·å®šä¹‰çš„è¯·æ±‚ ----
    query = "è¯·å¸®æˆ‘è®¡ç®— (15 + 27) * 3 - 18 / 6 ç­‰äºå¤šå°‘ï¼Ÿ"
    print(f"\nç”¨æˆ·é—®é¢˜ï¼š{query}")
    print("-" * 40)

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©è®¡ç®—ã€‚"},
        {"role": "user", "content": query},
    ]

    # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šLLM å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
    print("\n[ç¬¬ 1 æ¬¡ LLM è°ƒç”¨] å‘é€é—®é¢˜ + å·¥å…·å®šä¹‰...")
    response = llm.chat(messages, tools=tools)
    message = response.choices[0].message

    print(f"  LLM å›å¤å†…å®¹ï¼š{message.content or '(æ— æ–‡æœ¬ï¼Œå‡†å¤‡è°ƒç”¨å·¥å…·)'}")
    print(f"  æ˜¯å¦è°ƒç”¨å·¥å…·ï¼š{'æ˜¯' if message.tool_calls else 'å¦'}")

    if not message.tool_calls:
        print(f"\nLLM ç›´æ¥å›ç­”äº†ï¼Œæ— éœ€è°ƒç”¨å·¥å…·ã€‚")
        return

    # ---- æ­¥éª¤ 3ï¼šæ‰§è¡Œå·¥å…·è°ƒç”¨ ----
    tool_call = message.tool_calls[0]
    func_name = tool_call.function.name
    func_args = json.loads(tool_call.function.arguments)

    print(f"\n  å·¥å…·åç§°ï¼š{func_name}")
    print(f"  å·¥å…·å‚æ•°ï¼š{func_args}")

    # æ‰‹åŠ¨æ‰§è¡Œå·¥å…·
    result = calculator.run(**func_args)
    print(f"  å·¥å…·ç»“æœï¼š{result}")

    # ---- æ­¥éª¤ 4ï¼šå°†å·¥å…·ç»“æœè¿”å›ç»™ LLM ----
    # å¿…é¡»æŒ‰ OpenAI æ ¼å¼æ‹¼è£… assistant + tool æ¶ˆæ¯
    messages.append({
        "role": "assistant",
        "content": message.content,
        "tool_calls": [
            {
                "id": tool_call.id,
                "type": "function",
                "function": {
                    "name": func_name,
                    "arguments": tool_call.function.arguments,
                },
            }
        ],
    })
    messages.append({
        "role": "tool",
        "tool_call_id": tool_call.id,
        "content": result,
    })

    print(f"\n[ç¬¬ 2 æ¬¡ LLM è°ƒç”¨] å‘é€å·¥å…·ç»“æœï¼Œè·å–æœ€ç»ˆå›ç­”...")
    response2 = llm.chat(messages, tools=tools)
    final_answer = response2.choices[0].message.content

    print(f"\næœ€ç»ˆå›ç­”ï¼š{final_answer}")
    print("=" * 60)

    # ---- çŸ¥è¯†ç‚¹æ€»ç»“ ----
    print("\nğŸ“ çŸ¥è¯†ç‚¹æ€»ç»“ï¼š")
    print("1. å·¥å…·å®šä¹‰é€šè¿‡ tools å‚æ•°ä¼ ç»™ LLM")
    print("2. LLM è¿”å› tool_calls è¡¨ç¤ºå®ƒæƒ³è°ƒç”¨å·¥å…·")
    print("3. æˆ‘ä»¬æ‰§è¡Œå·¥å…·åï¼Œå°†ç»“æœä»¥ tool è§’è‰²æ¶ˆæ¯è¿”å›")
    print("4. LLM æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”")
    print("5. æ•´ä¸ªè¿‡ç¨‹éœ€è¦ 2 æ¬¡ LLM è°ƒç”¨")


if __name__ == "__main__":
    main()
